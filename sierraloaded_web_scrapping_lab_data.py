# -*- coding: utf-8 -*-
"""SierraLoaded Web Scrapping Lab Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P3RZ4Gos_L0ACrm1rU0uEEumF_5OSxqT
"""

pip install requests beautifulsoup4

import requests

#Send an HTTP GET request
url = "https://sierraloaded.sl/"
response = requests.get(url)

#Check the response status code
print ("Response Status Code:", response.status_code)

#Print the first 500 characters of the response content
print("Response Content")
print(response.text[:500])

from bs4 import BeautifulSoup

# Parse the HTML Content
soup = BeautifulSoup(response.content, "html.parser")

# Find the first <h1> tag and extract its text
header = soup.find("h2")
print("Header:", header)

# Find all <a> tags and extract their href attributes
links = soup.find_all("a")
for link in links:
  print("Link:", link.get("href"))

import os

url = "https://sierraloaded.sl/"

response = requests.get(url)

if response.status_code == 200:
  soup = BeautifulSoup(response.content, 'html.parser')

  # Scrape images
  image_folder = 'images'
  os.makedirs(image_folder, exist_ok=True)
  image_tags = soup.find_all('img')


  for img_tag in image_tags:
    img_url = img_tag['src']
    if not img_url.startswith('http'):
      img_url = url + img_url
    img_response = requests.get(img_url)

    # Save the image to the images folder
    with open(os.path.join(image_folder, os.path.basename(img_url)), 'wb') as img_file:
      img_file.write(img_response.content)


  # Scrap text
  text_data = []
  text_tags = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'span', 'div'])

  for tag in text_tags:
    text_data.append(tag.get_text())


  # Print the text data
  print ("/n".join(text_data))



else:
  print(f"Failed to fetch data from {url}. Status Code: {response.status_code}")